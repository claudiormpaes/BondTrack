"""
Auditoria de Dados - Data Quality Center
"""
import streamlit as st
import sys
import os
import pandas as pd

# Adiciona o diret√≥rio src ao path
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(__file__)), 'src'))

import data_engine as engine
import visuals
import sidebar_utils

st.set_page_config(page_title="Auditoria de Dados", page_icon="üîé", layout="wide")

# CSS Customizado
st.markdown("""
<style>
    [data-testid="stMetricValue"] {
        font-size: 1.5rem;
        font-weight: 700;
    }
    h1, h2, h3 {
        color: #EF553B;
    }
    .score-alto {
        color: #00CC96;
        font-size: 3rem;
        font-weight: 900;
    }
    .score-medio {
        color: #FFA15A;
        font-size: 3rem;
        font-weight: 900;
    }
    .score-baixo {
        color: #EF553B;
        font-size: 3rem;
        font-weight: 900;
    }
</style>
""", unsafe_allow_html=True)

# ===== SIDEBAR =====
with st.sidebar:
    sidebar_utils.render_logo()
    st.title("Auditoria de Dados")
    
    datas_disponiveis = engine.get_available_dates()
    
    if not datas_disponiveis:
        st.error("Nenhuma data dispon√≠vel")
        st.stop()
    
    data_ref = st.selectbox("Data de Refer√™ncia", datas_disponiveis)
    
    st.divider()
    
    st.markdown("""
    ### O que analisamos?
    
    - **Completude:** % de campos preenchidos
    - **Duplica√ß√£o:** Ativos repetidos
    - **Inconsist√™ncias:** Taxas/durations negativas
    - **Cobertura:** SND vs Anbima
    """)

# ===== CARREGAR DADOS =====
df_full, erro = engine.load_data(data_ref)

if erro or df_full is None or df_full.empty:
    st.error(f"‚ùå Erro ao carregar dados: {erro}")
    st.stop()

# ===== CONTE√öDO PRINCIPAL =====
st.title("üîé Centro de Auditoria e Qualidade de Dados")
st.markdown(f"**Data de Refer√™ncia:** {data_ref}")

st.divider()

# ===== SCORE DE QUALIDADE =====
st.markdown("### üéØ Score de Qualidade dos Dados")

report = engine.get_data_quality_report(df_full)

score = report['score_qualidade']

# Determinar classe CSS baseada no score
if score >= 80:
    score_class = "score-alto"
    emoji = "üéâ"
    status = "Excelente"
elif score >= 60:
    score_class = "score-medio"
    emoji = "‚ö†Ô∏è"
    status = "Bom"
else:
    score_class = "score-baixo"
    emoji = "‚ùå"
    status = "Cr√≠tico"

col_score1, col_score2, col_score3 = st.columns([1, 2, 1])

with col_score2:
    st.markdown(f"<div style='text-align: center;'><p class='{score_class}'>{emoji} {score:.1f}/100</p><p style='font-size: 1.5rem;'>{status}</p></div>", unsafe_allow_html=True)

st.divider()

# ===== M√âTRICAS GERAIS =====
st.markdown("### üìä M√©tricas Gerais")

col_m1, col_m2, col_m3, col_m4 = st.columns(4)

with col_m1:
    st.metric("Total de Registros", f"{report['total_registros']:,}")

with col_m2:
    st.metric("Duplicatas Detectadas", f"{report['duplicatas']}", delta=f"{(report['duplicatas']/report['total_registros']*100):.1f}%" if report['total_registros'] > 0 else "0%")

with col_m3:
    inconsist_count = len(report['inconsistencias'])
    st.metric("Inconsist√™ncias", f"{inconsist_count}")

with col_m4:
    snd_anbima = len(df_full[df_full['FONTE'] == 'SND + Anbima'])
    cobertura = (snd_anbima / report['total_registros'] * 100) if report['total_registros'] > 0 else 0
    st.metric("Cobertura SND+Anbima", f"{cobertura:.1f}%")

st.divider()

# ===== COMPLETUDE POR CAMPO =====
st.markdown("### üìã An√°lise de Completude por Campo")

if report['campos_completos']:
    completude_data = []
    for campo, stats in report['campos_completos'].items():
        completude_data.append({
            'Campo': campo.upper(),
            'V√°lidos': stats['validos'],
            'Inv√°lidos': stats['invalidos'],
            'Completude (%)': stats['percentual']
        })
    
    df_completude = pd.DataFrame(completude_data)
    
    # Gr√°fico de barras
    import plotly.graph_objects as go
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='V√°lidos',
        x=df_completude['Campo'],
        y=df_completude['V√°lidos'],
        marker_color='#00CC96'
    ))
    
    fig.add_trace(go.Bar(
        name='Inv√°lidos',
        x=df_completude['Campo'],
        y=df_completude['Inv√°lidos'],
        marker_color='#EF553B'
    ))
    
    fig.update_layout(
        barmode='stack',
        title='Completude de Campos Cr√≠ticos',
        xaxis_title='Campo',
        yaxis_title='Quantidade',
        template='plotly_dark',
        paper_bgcolor='#0e1117',
        plot_bgcolor='#0e1117',
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Tabela detalhada
    st.dataframe(
        df_completude.style.format({'Completude (%)': '{:.2f}%'}),
        hide_index=True,
        use_container_width=True
    )
else:
    st.warning("‚ö†Ô∏è Nenhum dado de completude dispon√≠vel")

st.divider()

# ===== LOG DE INCONSIST√äNCIAS =====
st.markdown("### ‚ö†Ô∏è Log de Inconsist√™ncias")

if report['inconsistencias']:
    for inconsistencia in report['inconsistencias']:
        st.warning(f"‚ö†Ô∏è {inconsistencia}")
else:
    st.success("‚úÖ Nenhuma inconsist√™ncia detectada!")

st.divider()

# ===== DUPLICATAS =====
st.markdown("### üîÑ An√°lise de Duplicatas")

if report['duplicatas'] > 0:
    # Encontrar duplicatas
    if 'codigo' in df_full.columns and 'data_referencia' in df_full.columns:
        df_duplicatas = df_full[df_full.duplicated(subset=['codigo', 'data_referencia'], keep=False)]
        df_duplicatas = df_duplicatas.sort_values(['codigo', 'data_referencia'])
        
        st.warning(f"‚ö†Ô∏è {report['duplicatas']} registros duplicados encontrados")
        
        cols_dup = ['codigo', 'emissor', 'data_referencia', 'taxa', 'duration', 'FONTE']
        cols_disponiveis = [c for c in cols_dup if c in df_duplicatas.columns]
        
        st.dataframe(
            df_duplicatas[cols_disponiveis],
            hide_index=True,
            use_container_width=True,
            height=300
        )
        
        st.info("""
        üí° **A√ß√£o Recomendada:**
        - Duplicatas podem ocorrer por m√∫ltiplas fontes (SND + Anbima)
        - Verifique se os dados s√£o realmente duplicados ou apenas cruzamento de fontes
        - Considere implementar regra de deduplica√ß√£o no ETL
        """)
else:
    st.success("‚úÖ Nenhuma duplicata detectada!")

st.divider()

# ===== DISTRIBUI√á√ÉO POR FONTE =====
st.markdown("### üìä Distribui√ß√£o por Fonte de Dados")

col_fonte1, col_fonte2 = st.columns([2, 1])

with col_fonte1:
    fig_fonte = visuals.create_pie_distribuicao(
        df_full,
        names_col='FONTE',
        title="Distribui√ß√£o de Registros por Fonte",
        hole=0.4
    )
    st.plotly_chart(fig_fonte, use_container_width=True)

with col_fonte2:
    st.markdown("#### Detalhamento")
    
    fonte_counts = df_full['FONTE'].value_counts()
    for fonte, count in fonte_counts.items():
        pct = (count / report['total_registros'] * 100)
        st.metric(
            label=fonte,
            value=f"{count:,}",
            delta=f"{pct:.1f}%"
        )
    
    st.info("""
    **Legenda:**
    - **SND + Anbima:** Dados consolidados
    - **Anbima:** Apenas mercado secund√°rio
    - **SND:** Apenas cadastro
    """)

st.divider()

# ===== CAMPOS VAZIOS POR ATIVO =====
st.markdown("### üîç Ativos com Mais Campos Vazios")

# Contar campos vazios por ativo
campos_analise = ['taxa', 'duration', 'pu', 'vencimento', 'emissao']
campos_disponiveis = [c for c in campos_analise if c in df_full.columns]

if campos_disponiveis:
    df_full['campos_vazios'] = df_full[campos_disponiveis].isna().sum(axis=1)
    df_top_vazios = df_full.nlargest(10, 'campos_vazios')[['codigo', 'emissor', 'campos_vazios', 'FONTE']]
    
    st.dataframe(
        df_top_vazios,
        hide_index=True,
        use_container_width=True,
        column_config={
            "campos_vazios": "Campos Vazios (de " + str(len(campos_disponiveis)) + ")"
        }
    )
    
    st.info("""
    üí° **Interpreta√ß√£o:**
    - Ativos apenas do cadastro SND ter√£o mais campos vazios (sem pre√ßo de mercado)
    - Ativos consolidados (SND + Anbima) devem ter completude maior
    """)
else:
    st.warning("‚ö†Ô∏è Campos de an√°lise n√£o dispon√≠veis")

st.divider()

# ===== RECOMENDA√á√ïES =====
st.markdown("### üí° Recomenda√ß√µes")

if score >= 80:
    st.success("""
    ‚úÖ **Qualidade Excelente!**
    
    - Dados est√£o em √≥timo estado
    - Continue monitorando diariamente
    - Considere expandir fontes de dados
    """)
elif score >= 60:
    st.warning("""
    ‚ö†Ô∏è **Qualidade Boa, mas pode melhorar:**
    
    - Revise campos com baixa completude
    - Investigue duplicatas
    - Automatize valida√ß√µes no ETL
    """)
else:
    st.error("""
    ‚ùå **Qualidade Cr√≠tica - A√ß√£o Necess√°ria:**
    
    - Revisar processo de ETL urgentemente
    - Corrigir inconsist√™ncias detectadas
    - Implementar valida√ß√µes autom√°ticas
    - Considerar re-importa√ß√£o dos dados
    """)

st.divider()

# ===== EXPORT DE RELAT√ìRIO =====
st.markdown("### üíæ Exportar Relat√≥rio")

if st.button("üìä Gerar Relat√≥rio Completo (JSON)"):
    import json
    
    relatorio_json = json.dumps(report, indent=2, ensure_ascii=False)
    
    st.download_button(
        label="üíæ Download Relat√≥rio JSON",
        data=relatorio_json,
        file_name=f"bondtrack_auditoria_{data_ref.replace('/', '')}.json",
        mime='application/json'
    )
    
    st.success("‚úÖ Relat√≥rio gerado com sucesso!")
